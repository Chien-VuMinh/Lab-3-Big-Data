{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "25/04/11 14:18:31 WARN Utils: Your hostname, Cp resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/04/11 14:18:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/11 14:18:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/04/11 14:18:43 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = sc.textFile(\"file:///home/cap/hadoop/hadoop-3.4.1/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "\n",
    "As we have analysed in Structured API section, this data has a very high bias so we reduce the label 0's data down to 500 so the dataset can be more balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing values: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# remove header and read data\n",
    "header = raw_data.first()\n",
    "data = raw_data.filter(lambda line: line != header)\n",
    "parsedData = data.map(\\\n",
    "                lambda line: [float(x.strip('\"')) for x in line.split(\",\")])\n",
    "\n",
    "# check missing value\n",
    "def has_missing(row):\n",
    "    for item in row:\n",
    "        if item is None:\n",
    "            return True\n",
    "        if isinstance(item, str) and (item == \"\" or item.lower() in ['na', 'null', 'nan']):\n",
    "            return True\n",
    "    return False\n",
    "missing_rows = parsedData.filter(has_missing).count()\n",
    "print(f\"Rows with missing values: {missing_rows}\")\n",
    "\n",
    "# remove duplicate values\n",
    "rdd_data = parsedData.map(lambda cols: (tuple(cols[:-1]), cols[-1])).distinct()\n",
    "rdd_data = rdd_data.map(lambda x: list((list(*x[:-1],), x[-1])))\n",
    "\n",
    "\n",
    "# prepare data in proper format\n",
    "def prepare_features(fields):\n",
    "    features = [1.0] + fields[:-1][0]\n",
    "    label = fields[-1]              \n",
    "    return (features, label)\n",
    "rdd_data = rdd_data.map(prepare_features).cache()\n",
    "\n",
    "\n",
    "# fill 1 and 0 labels\n",
    "data_0 = rdd_data.filter(lambda x: x[1] == 0.0)\n",
    "data_1 = rdd_data.filter(lambda x: x[1] == 1.0)\n",
    "\n",
    "# set seed\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "\n",
    "# get random sample\n",
    "data_0_count = data_0.count()\n",
    "sample_ratio = 600 / data_0_count\n",
    "data_0_sampled = data_0.sample(withReplacement=False, fraction=sample_ratio, seed=seed).take(500)\n",
    "data_0_rdd = sc.parallelize(data_0_sampled)\n",
    "\n",
    "rdd_data = data_0_rdd.union(data_1)\n",
    "\n",
    "\n",
    "\n",
    "# split to train and test set\n",
    "train, test = rdd_data.randomSplit(weights=[0.8, 0.2], seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def normalize_zscore(rdd):\n",
    "    # get features from RDD\n",
    "    features_rdd = rdd.map(lambda x: x[0])\n",
    "\n",
    "    # mean and std\n",
    "    num_features = len(features_rdd.first())\n",
    "    means = [features_rdd.map(lambda x: x[i]).mean() for i in range(num_features)]\n",
    "    stds = [features_rdd.map(lambda x: x[i]).stdev() for i in range(num_features)]\n",
    "\n",
    "    def zscore(features, means, stds):\n",
    "        return [(f - means[i]) / stds[i] if stds[i] != 0 else 0 for i, f in enumerate(features)]\n",
    "\n",
    "\n",
    "    # normalize\n",
    "    normalized_rdd = rdd.map(lambda x: (zscore(x[0], means, stds), x[1]))\n",
    "    return normalized_rdd\n",
    "\n",
    "train = normalize_zscore(train)\n",
    "test = normalize_zscore(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot(weights, features):\n",
    "    return sum(w * f for w, f in zip(weights, features))\n",
    "\n",
    "def sigmoid(z):\n",
    "    try:\n",
    "        return 1.0 / (1.0 + math.exp(-z))\n",
    "    except OverflowError:\n",
    "        return 0.0 if z < 0 else 1.0\n",
    "\n",
    "def compute_gradient(weights, features, label):\n",
    "    z = dot(weights, features)\n",
    "    prediction = sigmoid(z)\n",
    "    error = prediction - label\n",
    "    return [error * f for f in features]\n",
    "\n",
    "\n",
    "def logistic_regression(data_rdd, learning_rate=0.01, iterations=20, batch_size=32):\n",
    "    num_features = len(data_rdd.first()[0])\n",
    "    # generate random weights\n",
    "    weights = [random.uniform(-0.01, 0.01) for _ in range(num_features)]\n",
    "\n",
    "    batched_rdd = data_rdd.zipWithIndex().groupBy(lambda x: x[1] // batch_size).mapValues(list)\n",
    "    batches = batched_rdd.map(lambda x: [item[0] for item in x[1]]).collect()\n",
    "\n",
    "    for epoch in range(iterations):\n",
    "        for batch in batches:\n",
    "            gradients = sc.parallelize(batch).map(lambda x: compute_gradient(weights, x[0], x[1]))\n",
    "            avg_gradient = gradients.reduce(lambda a, b: [x + y for x, y in zip(a, b)])\n",
    "            avg_gradient = [g / len(batch) for g in avg_gradient]\n",
    "            weights = [w - learning_rate * g  for w, g in zip(weights, avg_gradient)]\n",
    "\n",
    "        train_pred = data_rdd.map(lambda x: (1 if sigmoid(dot(weights, x[0])) >= 0.5 else 0, x[1]))\n",
    "        train_acc = train_pred.filter(lambda x: x[0] == x[1]).count() / data_rdd.count()\n",
    "        print(f\"Epoch {epoch+1}, Train Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model\n",
    "\n",
    "Here I will experiment with two diffenrent learning rate (0.01 and 0.1) and 2 different epoch (1 and 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-Level Operations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Accuracy: 0.8642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Accuracy: 0.8756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Accuracy: 0.8782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Accuracy: 0.8782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Accuracy: 0.8782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Accuracy: 0.8794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Accuracy: 0.8807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Accuracy: 0.8807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Accuracy: 0.8820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Accuracy: 0.8820\n",
      "Threshold 0.3: Accuracy=0.5297, Precision=0.5297, Recall=1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.4: Accuracy=0.8865, Precision=0.8738, Recall=0.9184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.5: Accuracy=0.8595, Precision=1.0000, Recall=0.7347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.6: Accuracy=0.6865, Precision=1.0000, Recall=0.4082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print('Low-Level Operations')\n",
    "\n",
    "\n",
    "# lr = 0.1, epoch = 20\n",
    "final_weights = logistic_regression(train, learning_rate=0.001, iterations=10, batch_size=32)\n",
    "\n",
    "# evaluate on test set\n",
    "def evaluate_with_threshold(predictions_rdd, threshold):\n",
    "    binary_pred = predictions_rdd.map(lambda x: (1 if x[0] >= threshold else 0, x[1]))\n",
    "    accuracy = binary_pred.filter(lambda x: x[0] == x[1]).count() / test.count()\n",
    "    tp = binary_pred.filter(lambda x: x[0] == 1 and x[1] == 1).count()\n",
    "    fp = binary_pred.filter(lambda x: x[0] == 1 and x[1] == 0).count()\n",
    "    fn = binary_pred.filter(lambda x: x[0] == 0 and x[1] == 1).count()\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    return accuracy, precision, recall\n",
    "\n",
    "predictions_rdd = test.map(lambda x: (sigmoid(dot(final_weights, x[0])), x[1]))\n",
    "for t in [0.3, 0.4, 0.5, 0.6]:\n",
    "    acc, prec, rec = evaluate_with_threshold(predictions_rdd, t)\n",
    "    print(f\"Threshold {t}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-Level Operations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Accuracy: 0.8909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Accuracy: 0.8959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Accuracy: 0.8959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Accuracy: 0.8972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Accuracy: 0.8985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Accuracy: 0.9048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Accuracy: 0.9086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Accuracy: 0.9124\n",
      "Epoch 9, Train Accuracy: 0.9162\n",
      "Epoch 10, Train Accuracy: 0.9162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Train Accuracy: 0.9188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Accuracy: 0.9175\n",
      "Epoch 13, Train Accuracy: 0.9201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Train Accuracy: 0.9201\n",
      "Epoch 15, Train Accuracy: 0.9201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Accuracy: 0.9175\n",
      "Epoch 17, Train Accuracy: 0.9175\n",
      "Epoch 18, Train Accuracy: 0.9188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Train Accuracy: 0.9188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train Accuracy: 0.9188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.3: Accuracy=0.9189, Precision=0.9663, Recall=0.8776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.4: Accuracy=0.9243, Precision=0.9884, Recall=0.8673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.5: Accuracy=0.9081, Precision=0.9880, Recall=0.8367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.6: Accuracy=0.8757, Precision=1.0000, Recall=0.7653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print('Low-Level Operations')\n",
    "\n",
    "\n",
    "# lr = 0.1, epoch = 20\n",
    "final_weights = logistic_regression(train, learning_rate=0.1, iterations=20, batch_size=32)\n",
    "\n",
    "# evaluate on test set\n",
    "def evaluate_with_threshold(predictions_rdd, threshold):\n",
    "    binary_pred = predictions_rdd.map(lambda x: (1 if x[0] >= threshold else 0, x[1]))\n",
    "    accuracy = binary_pred.filter(lambda x: x[0] == x[1]).count() / test.count()\n",
    "    tp = binary_pred.filter(lambda x: x[0] == 1 and x[1] == 1).count()\n",
    "    fp = binary_pred.filter(lambda x: x[0] == 1 and x[1] == 0).count()\n",
    "    fn = binary_pred.filter(lambda x: x[0] == 0 and x[1] == 1).count()\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    return accuracy, precision, recall\n",
    "\n",
    "predictions_rdd = test.map(lambda x: (sigmoid(dot(final_weights, x[0])), x[1]))\n",
    "for t in [0.3, 0.4, 0.5, 0.6]:\n",
    "    acc, prec, rec = evaluate_with_threshold(predictions_rdd, t)\n",
    "    print(f\"Threshold {t}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
