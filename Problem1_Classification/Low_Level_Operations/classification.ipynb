{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "25/04/05 09:23:15 WARN Utils: Your hostname, Cp resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/04/05 09:23:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/05 09:23:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = sc.textFile(\"file:///home/cap/hadoop/hadoop-3.4.1/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:===========>                                               (1 + 4) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing values: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# remove header and read data\n",
    "header = raw_data.first()\n",
    "data = raw_data.filter(lambda line: line != header)\n",
    "parsedData = data.map(\\\n",
    "                lambda line: [float(x.strip('\"')) for x in line.split(\",\")])\n",
    "\n",
    "# check missing value\n",
    "def has_missing(row):\n",
    "    for item in row:\n",
    "        if item is None:\n",
    "            return True\n",
    "        if isinstance(item, str) and (item == \"\" or item.lower() in ['na', 'null', 'nan']):\n",
    "            return True\n",
    "    return False\n",
    "missing_rows = parsedData.filter(has_missing).count()\n",
    "print(f\"Rows with missing values: {missing_rows}\")\n",
    "\n",
    "# remove duplicate values\n",
    "rdd_data = parsedData.map(lambda cols: (tuple(cols[:-1]), cols[-1])).distinct()\n",
    "rdd_data = rdd_data.map(lambda x: list((list(*x[:-1],), x[-1])))\n",
    "\n",
    "\n",
    "# prepare data in proper format\n",
    "def prepare_features(fields):\n",
    "    features = [1.0] + fields[:-1][0]\n",
    "    label = fields[-1]              \n",
    "    return (features, label)\n",
    "rdd_data = rdd_data.map(prepare_features).cache()\n",
    "\n",
    "# split to train and test set\n",
    "train, test = rdd_data.randomSplit(weights=[0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid function\n",
    "def sigmoid(x):\n",
    "    if x < -100:\n",
    "        return 0.0\n",
    "    elif x > 100: \n",
    "        return 1.0\n",
    "    return 1.0 / (1.0 + math.exp(-x))\n",
    "\n",
    "# dot function\n",
    "def dot(features, weights):\n",
    "    return sum(f * w for f, w in zip(features, weights))\n",
    "\n",
    "# predict\n",
    "def predict(features, weights):\n",
    "    return sigmoid(dot(features, weights))\n",
    "\n",
    "# sgd\n",
    "def compute_gradient(features, label, weights):\n",
    "    prediction = predict(features, weights)\n",
    "    error = label - prediction\n",
    "    gradient = [error * f for f in features]\n",
    "    return gradient\n",
    "\n",
    "\n",
    "# training model\n",
    "def logistic_regression(data_rdd, learning_rate=0.1, iterations=100):\n",
    "    # initialize weights\n",
    "    num_features = len(data_rdd.first()[0])\n",
    "    weights = [0.0] * num_features\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        # sgd for the dataset\n",
    "        gradients = data_rdd.map(lambda x: compute_gradient(x[0], x[1], weights))\n",
    "        \n",
    "        # average gradient\n",
    "        avg_gradient = gradients.reduce(lambda a, b: [x + y for x, y in zip(a, b)])\n",
    "        avg_gradient = [g / data_rdd.count() for g in avg_gradient]\n",
    "        \n",
    "        # update weight\n",
    "        weights = [w + learning_rate * g for w, g in zip(weights, avg_gradient)]\n",
    "\n",
    "        \n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model\n",
    "\n",
    "Here I will experiment with two diffenrent learning rate (0.01 and 0.1) and 2 different epoch (1 and 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-Level Operations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/05 09:31:35 WARN BlockManager: Task 257 already completed, not releasing lock for rdd_8_0\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 0.01, epoch = 1 --> Accuracy: 0.9985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/05 09:31:46 WARN BlockManager: Task 428 already completed, not releasing lock for rdd_8_0\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 0.1, epoch = 1 --> Accuracy: 0.9985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/05 09:31:56 WARN BlockManager: Task 599 already completed, not releasing lock for rdd_8_0\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 0.01, epoch = 20 --> Accuracy: 0.9985\n"
     ]
    }
   ],
   "source": [
    "print('Low-Level Operations')\n",
    "# lr = 0.01, epoch = 1\n",
    "final_weights = logistic_regression(train, learning_rate=0.01, iterations=1)\n",
    "\n",
    "predictions_rdd = test.map(lambda x: (sigmoid(dot(final_weights, x[0])), x[1]))\n",
    "binary_predictions_rdd = predictions_rdd.map(lambda x: (1 if x[0] >= 0.5 else 0, x[1]))\n",
    "correct_predictions = binary_predictions_rdd.filter(lambda x: x[0] == x[1]).count()\n",
    "total_samples = test.count()\n",
    "accuracy = correct_predictions / total_samples\n",
    "print(f\"lr = 0.01, epoch = 1 --> Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# lr = 0.1, epoch = 1\n",
    "final_weights = logistic_regression(train, learning_rate=0.1, iterations=1)\n",
    "\n",
    "predictions_rdd = test.map(lambda x: (sigmoid(dot(final_weights, x[0])), x[1]))\n",
    "binary_predictions_rdd = predictions_rdd.map(lambda x: (1 if x[0] >= 0.5 else 0, x[1]))\n",
    "correct_predictions = binary_predictions_rdd.filter(lambda x: x[0] == x[1]).count()\n",
    "total_samples = test.count()\n",
    "accuracy = correct_predictions / total_samples\n",
    "print(f\"lr = 0.1, epoch = 1 --> Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# lr = 0.01, epoch = 20\n",
    "final_weights = logistic_regression(train, learning_rate=0.01, iterations=20)\n",
    "\n",
    "predictions_rdd = test.map(lambda x: (sigmoid(dot(final_weights, x[0])), x[1]))\n",
    "binary_predictions_rdd = predictions_rdd.map(lambda x: (1 if x[0] >= 0.5 else 0, x[1]))\n",
    "correct_predictions = binary_predictions_rdd.filter(lambda x: x[0] == x[1]).count()\n",
    "total_samples = test.count()\n",
    "accuracy = correct_predictions / total_samples\n",
    "print(f\"lr = 0.01, epoch = 20 --> Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# lr = 0.1, epoch = 20\n",
    "final_weights = logistic_regression(train, learning_rate=0.1, iterations=20)\n",
    "\n",
    "predictions_rdd = test.map(lambda x: (sigmoid(dot(final_weights, x[0])), x[1]))\n",
    "binary_predictions_rdd = predictions_rdd.map(lambda x: (1 if x[0] >= 0.5 else 0, x[1]))\n",
    "correct_predictions = binary_predictions_rdd.filter(lambda x: x[0] == x[1]).count()\n",
    "total_samples = test.count()\n",
    "accuracy = correct_predictions / total_samples\n",
    "print(f\"lr = 0.1, epoch = 20 --> Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0\n",
      "Recall: 0.0\n",
      "True positive: 0\n",
      "False positive: 0\n"
     ]
    }
   ],
   "source": [
    "# Tính TP, FP, TN, FN\n",
    "tp = binary_predictions_rdd.filter(lambda x: x[0] == 1 and x[1] == 1).count()\n",
    "fp = binary_predictions_rdd.filter(lambda x: x[0] == 1 and x[1] == 0).count()\n",
    "tn = binary_predictions_rdd.filter(lambda x: x[0] == 0 and x[1] == 0).count()\n",
    "fn = binary_predictions_rdd.filter(lambda x: x[0] == 0 and x[1] == 1).count()\n",
    "\n",
    "# Tính Precision và Recall\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"True positive: {tp}\")\n",
    "print(f\"False positive: {fp}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
